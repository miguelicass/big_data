{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6873211b02d4"
   },
   "source": [
    "#### Import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-02T16:35:22.863599Z",
     "iopub.status.busy": "2020-10-02T16:35:22.863030Z",
     "iopub.status.idle": "2020-10-02T16:35:28.261974Z",
     "shell.execute_reply": "2020-10-02T16:35:28.261435Z"
    },
    "id": "71c626bbac35"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4041a2e9b310"
   },
   "source": [
    "## Simple Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98e0c38cf95d"
   },
   "source": [
    "There are three built-in RNN layers in Keras:\n",
    "\n",
    "1. [`keras.layers.SimpleRNN`](https://keras.io/api/layers/recurrent_layers/simple_rnn/), a fully-connected RNN where the output from previous\n",
    "timestep is to be fed to next timestep.\n",
    "\n",
    "```python\n",
    "tf.keras.layers.SimpleRNN(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "````\n",
    "\n",
    "2. [`keras.layers.GRU`](https://keras.io/api/layers/recurrent_layers/gru/), first proposed in\n",
    "[Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
    "```python\n",
    "tf.keras.layers.GRU(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "```\n",
    "\n",
    "3. [`keras.layers.LSTM`](https://keras.io/api/layers/recurrent_layers/lstm/), first proposed in\n",
    "[Hochreiter & Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n",
    "```python\n",
    "tf.keras.layers.LSTM(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    ")\n",
    "````\n",
    "For more information, see the\n",
    "[RNN API documentation](https://keras.io/api/layers/recurrent_layers/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In time series forecasting we are going to use the **many-to-one** architecture with default parameter `return_sequences=False`.\n",
    "\n",
    "The shape of the output  for this architecture  is `(batch_size, units)`.\n",
    "where `units` corresponds to the `units` argument passed to the layer's constructor.\n",
    "\n",
    "Lets see one some examples for understanding the input/output dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-02T16:35:28.271135Z",
     "iopub.status.busy": "2020-10-02T16:35:28.270504Z",
     "iopub.status.idle": "2020-10-02T16:35:30.101802Z",
     "shell.execute_reply": "2020-10-02T16:35:30.102221Z"
    },
    "id": "a5617759e54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim (batch, timesteps, feature):  (32, 10, 4)\n",
      "return_state=False output shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "# dims of input: [batch, timesteps, features]\n",
    "inputs = tf.random.normal([32, 10, 4])\n",
    "print('input dim (batch, timesteps, feature): ', inputs.shape)\n",
    "# return_sequences=False, return_state=False\n",
    "lstm = tf.keras.layers.LSTM(units= 2)\n",
    "output = lstm(inputs)\n",
    "print('return_state=False output shape: ',output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RNN\n",
    "We can stack multiple layers of RNNs on top of each other. Each hidden state is continuously passed to both the next time step of the current layer and the current time step of the next layer.\n",
    "\n",
    "For stack another RNN layer to an existing one, we need to use the states with `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64)\n"
     ]
    }
   ],
   "source": [
    "## We can modify the input vector before the rnn cell with TimeDistributed\n",
    "timesteps = 10\n",
    "features = 8 # dimension of the innput of every cell\n",
    "\n",
    "#Shape [batch, timesteps, features] \n",
    "inputs = tf.keras.Input(shape=(timesteps, features), name='input')\n",
    "lstm_1 = layers.LSTM(64, return_sequences=True, name='lstm_1')(inputs)\n",
    "lstm_2 = layers.LSTM(64, return_sequences=True, name='lstm_2')(lstm_1)\n",
    "# last lstm layer depends in [one to many or  many to many]\n",
    "lstm_3 = layers.LSTM(64, return_sequences=False, name='lstm_3')(lstm_2)\n",
    "model = keras.Model(inputs=inputs, outputs=lstm_3, name='rnn_example')\n",
    "#print(model.summary())\n",
    "inputs = tf.random.normal([32, timesteps, features])\n",
    "print(model(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNNs\n",
    "\n",
    "For sequences other than time series (e.g. text), it is often the case that a RNN model\n",
    "can perform better if it not only processes sequence from start to end, but also\n",
    "backwards. For example, to predict the next word in a sentence, it is often useful to\n",
    "have the context around the word, not only just the words that come before it.\n",
    "\n",
    "Keras provides an easy API for you to build such bidirectional RNNs: the\n",
    "`keras.layers.Bidirectional` wrapper.\n",
    "\n",
    "[link to documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 10, 128)           37376     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 79,242\n",
      "Trainable params: 79,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# If you crete a second layer you must set return_sequences=True\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(timesteps, features))\n",
    ")\n",
    "# Second Bidirectional layer\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "# Output\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "attachments": {
    "split_window.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windowing sequences\n",
    "\n",
    "![split_window.png](attachment:split_window.png)\n",
    "\n",
    "Creates a dataset of sliding windows over a timeseries provided as array with [timeseries_dataset_from_array](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating the windows we use [timeseries_dataset_from_array](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)\n",
    "\n",
    "```python\n",
    "tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data, targets, sequence_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None\n",
    ")\n",
    "```\n",
    "\n",
    "For preprocessing the input we are going to use `prepare_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(ts, past, future, batch_size):\n",
    "    start = past + future - 1\n",
    "    x = ts[:-past + 1]\n",
    "    y = ts[start:start + len(x)]\n",
    "    # padding\n",
    "    y = np.concatenate([y, np.zeros(len(x) - len(y))])\n",
    "    dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        x,\n",
    "        y,\n",
    "        sequence_length=past,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airlines Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-efda0e7350f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMouseButton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigaspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParamsDefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParamsOrig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mpl_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/projections/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAitoffAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHammerAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambertAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMollweideAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolarAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/axes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_subplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_axes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m \u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmartist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdedent_interpd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mkwdoc\u001b[0;34m(artist)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     return ('\\n'.join(ai.pprint_setters_rest(leadingspace=4))\n\u001b[1;32m   1631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'docstring.hardcopy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m             'Properties:\\n' + '\\n'.join(ai.pprint_setters(leadingspace=4)))\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mpprint_setters\u001b[0;34m(self, prop, leadingspace)\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_setters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             \u001b[0maccepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_valid_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maliased_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mget_valid_values\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_valid_values_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n *\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/airline-passengers.csv', usecols=[1])\n",
    "url = 'https://c4science.ch/diffusion/2096/browse/master/input/international-airline-passengers.csv'\n",
    "df = pd.read_csv(url, usecols=[1], nrows=144)\n",
    "dataset = df.values  # .flatten()\n",
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train/test set and scale with  StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.75\n",
    "train_split = int(split_fraction * int(len(dataset)))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset[:train_split])\n",
    "\n",
    "\n",
    "dataset_s = scaler.fit_transform(dataset).flatten()\n",
    "plt.plot(dataset_s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train, test = dataset_s[0:train_split], dataset_s[train_split:len(dataset)]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght of sequence for predicting\n",
    "past = 2\n",
    "# future steps to predict\n",
    "future = 1\n",
    "\n",
    "batch_size = 4\n",
    "dataset_train = prepare_dataset(train, past, future,\n",
    "                    batch_size)\n",
    "dataset_val = prepare_dataset(test, past, future,\n",
    "                    batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for windows, targets in dataset_train:\n",
    "    print('windows shape: {}'.format(windows.shape))\n",
    "    print('targets shape: {}'.format(targets.shape))\n",
    "    for i in range(len(targets)):\n",
    "        print('window,target: {},{}'.format(windows[i,:].numpy(), targets[i].numpy()))   \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape = (past, 1)\n",
    "inputs = keras.layers.Input(shape=(past,1))\n",
    "lstm_out_1 = keras.layers.LSTM(32, return_sequences=False)(inputs)\n",
    "outputs = keras.layers.Dense(1)(lstm_out_1)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=100,\n",
    "    validation_data=dataset_val\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x, y in dataset_val.take(5):\n",
    "    x_in = scaler.inverse_transform(x.numpy())\n",
    "    y_in = scaler.inverse_transform(y.numpy())\n",
    "    pred = scaler.inverse_transform(model.predict(x))\n",
    "    show_plot(\n",
    "        [x_in[0,:], y_in[0], pred.flatten()[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future steps to predict\n",
    "future = 1\n",
    "sequence_length = int(past)  # the that steps we use to predict\n",
    "\n",
    "x = dataset_s[:-past]\n",
    "# first target oof first window is len(window) + future\n",
    "y = dataset_s[past:]\n",
    "\n",
    "batch_size=200\n",
    "dataset_ts = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x, y, sequence_length=past, batch_size=batch_size)\n",
    "for x, y in dataset_ts:\n",
    "    x_in = scaler.inverse_transform(x.numpy())\n",
    "    y_in = scaler.inverse_transform(y.numpy())\n",
    "    pred = scaler.inverse_transform(model.predict(x))\n",
    "    \n",
    "plt.plot(y_in)\n",
    "plt.plot(pred)\n",
    "plt.legend(['Real','Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Data Time-Series\n",
    "\n",
    "We will be using Jena Climate dataset recorded by the\n",
    "[Max Planck Institute for Biogeochemistry](https://www.bgc-jena.mpg.de/wetter/).\n",
    "The dataset consists of 14 features such as temperature, pressure, humidity etc, recorded once per\n",
    "10 minutes.\n",
    "\n",
    "**Location**: Weather Station, Max Planck Institute for Biogeochemistry\n",
    "in Jena, Germany\n",
    "\n",
    "**Time-frame Considered**: Jan 10, 2009 - December 31, 2016\n",
    "\n",
    "\n",
    "The table below shows the column names, their value formats, and their description.\n",
    "\n",
    "Index| Features      |Format             |Description\n",
    "-----|---------------|-------------------|-----------------------\n",
    "1    |Date Time      |01.01.2009 00:10:00|Date-time reference\n",
    "2    |p (mbar)       |996.52             |The pascal SI derived unit of pressure used to quantify internal pressure. Meteorological reports typically state atmospheric pressure in millibars.\n",
    "3    |T (degC)       |-8.02              |Temperature in Celsius\n",
    "4    |Tpot (K)       |265.4              |Temperature in Kelvin\n",
    "5    |Tdew (degC)    |-8.9               |Temperature in Celsius relative to humidity. Dew Point is a measure of the absolute amount of water in the air, the DP is the temperature at which the air cannot hold all the moisture in it and water condenses.\n",
    "6    |rh (%)         |93.3               |Relative Humidity is a measure of how saturated the air is with water vapor, the %RH determines the amount of water contained within collection objects.\n",
    "7    |VPmax (mbar)   |3.33               |Saturation vapor pressure\n",
    "8    |VPact (mbar)   |3.11               |Vapor pressure\n",
    "9    |VPdef (mbar)   |0.22               |Vapor pressure deficit\n",
    "10   |sh (g/kg)      |1.94               |Specific humidity\n",
    "11   |H2OC (mmol/mol)|3.12               |Water vapor concentration\n",
    "12   |rho (g/m ** 3) |1307.75            |Airtight\n",
    "13   |wv (m/s)       |1.03               |Wind speed\n",
    "14   |max. wv (m/s)  |1.75               |Maximum wind speed\n",
    "15   |wd (deg)       |152.3              |Wind direction in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall()\n",
    "csv_path = \"jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates =['Date Time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Visualization\n",
    "\n",
    "To give us a sense of the data we are working with, each feature has been plotted below.\n",
    "This shows the distinct pattern of each feature over the time period from 2009 to 2016.\n",
    "It also shows where anomalies are present, which will be addressed during normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Pressure\",\n",
    "    \"Temperature\",\n",
    "    \"Temperature in Kelvin\",\n",
    "    \"Temperature (dew point)\",\n",
    "    \"Relative Humidity\",\n",
    "    \"Saturation vapor pressure\",\n",
    "    \"Vapor pressure\",\n",
    "    \"Vapor pressure deficit\",\n",
    "    \"Specific humidity\",\n",
    "    \"Water vapor concentration\",\n",
    "    \"Airtight\",\n",
    "    \"Wind speed\",\n",
    "    \"Maximum wind speed\",\n",
    "    \"Wind direction in degrees\",\n",
    "]\n",
    "\n",
    "feature_keys = [\n",
    "    \"p (mbar)\",\n",
    "    \"T (degC)\",\n",
    "    \"Tpot (K)\",\n",
    "    \"Tdew (degC)\",\n",
    "    \"rh (%)\",\n",
    "    \"VPmax (mbar)\",\n",
    "    \"VPact (mbar)\",\n",
    "    \"VPdef (mbar)\",\n",
    "    \"sh (g/kg)\",\n",
    "    \"H2OC (mmol/mol)\",\n",
    "    \"rho (g/m**3)\",\n",
    "    \"wv (m/s)\",\n",
    "    \"max. wv (m/s)\",\n",
    "    \"wd (deg)\",\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "date_time_key = \"Date Time\"\n",
    "\n",
    "\n",
    "def show_raw_visualization(data):\n",
    "    time_data = data[date_time_key]\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=7, ncols=2, figsize=(15, 20), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "    )\n",
    "    for i in range(len(feature_keys)):\n",
    "        key = feature_keys[i]\n",
    "        c = colors[i % (len(colors))]\n",
    "        t_data = data[key]\n",
    "        t_data.index = time_data\n",
    "        t_data.head()\n",
    "        ax = t_data.plot(\n",
    "            ax=axes[i // 2, i % 2],\n",
    "            color=c,\n",
    "            title=\"{} - {}\".format(titles[i], key),\n",
    "            rot=25,\n",
    "        )\n",
    "        ax.legend([titles[i]])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "show_raw_visualization(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heat map shows the correlation between different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(data):\n",
    "    plt.matshow(data.corr())\n",
    "    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_title = ['Pressure', 'Temperature', 'Saturation vapor pressure',\n",
    "                 'Vapor pressure deficit', 'Specific' 'humidity', 'Airtight', 'Wind speed']\n",
    "selected_features = ['p (mbar)',\n",
    " 'T (degC)',\n",
    " 'VPmax (mbar)',\n",
    " 'VPdef (mbar)',\n",
    " 'sh (g/kg)',\n",
    " 'rho (g/m**3)',\n",
    " 'wv (m/s)',\n",
    "\"max. wv (m/s)\",\"wd (deg)\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Here we are picking ~300,000 data points for training. Observation is recorded every\n",
    "10 mins, that means 6 times per hour. We will resample one point per hour since no\n",
    "drastic change is expected within 60 minutes. We do this via the `sampling_rate`\n",
    "argument in `timeseries_dataset_from_array` utility.\n",
    "\n",
    "We are tracking data from past 720 timestamps (720/6=120 hours). This data will be\n",
    "used to predict the temperature after 72 timestamps (76/6=12 hours).\n",
    "\n",
    "Since every feature has values with\n",
    "varying ranges, we do normalization to confine feature values to a range of `[0, 1]` before\n",
    "training a neural network.\n",
    "We do this by subtracting the mean and dividing by the standard deviation of each feature.\n",
    "\n",
    "71.5 % of the data will be used to train the model, i.e. 300,693 rows. `split_fraction` can\n",
    "be changed to alter this percentage.\n",
    "\n",
    "The model is shown data for first 5 days i.e. 720 observations, that are sampled every\n",
    "hour. The temperature after 72 (12 hours * 6 observation per hour) observation will be\n",
    "used as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('Date Time')\n",
    "## resample by the mean of hour values\n",
    "df =df.resample('1h').mean().fillna(method='ffill') # \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use only important features\n",
    "df_0 = df.copy()\n",
    "df = df[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the correlation heatmap, few parameters like Relative Humidity and\n",
    "Specific Humidity are redundant. Hence we will be using select features, not all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test\n",
    "split_fraction = 0.7\n",
    "train_split = int(split_fraction * int(len(df)))\n",
    "\n",
    "train_data = df.iloc[0 : train_split]\n",
    "val_data = df.iloc[train_split:]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, past, future,\n",
    "                    batch_size, target):\n",
    "    start = past + future - 1\n",
    "    x = df.iloc[:-past + 1]\n",
    "    y = df.iloc[start:start + len(x)][target].values.flatten()\n",
    "    # padding\n",
    "    y = np.concatenate([y, np.zeros(len(x) - len(y))])\n",
    "    dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        x,\n",
    "        y,\n",
    "        sequence_length=past,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `timeseries_dataset_from_array` function takes in a sequence of data-points gathered at\n",
    "equal intervals, along with time series parameters such as length of the\n",
    "sequences/windows, spacing between two sequence/windows, etc., to produce batches of\n",
    "sub-timeseries inputs and targets sampled from the main timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## previous hours to consider\n",
    "past = 6 # 1 * 24\n",
    "## Number of hours later to predict\n",
    "future = 12\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "dataset_train = prepare_dataset(train_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "dataset_val = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target= 'T (degC)')\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "    break\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n",
    "inputs_shape = (inputs.shape[1], inputs.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance\n",
    "\n",
    "Let's make sure to use buffered prefetching so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data.\n",
    "\n",
    "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "\n",
    "`Dataset.prefetch()` overlaps data preprocessing and model execution while training. \n",
    "\n",
    "Interested readers can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance#prefetching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "#dataset_train = dataset_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "#dataset_val = dataset_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization layer\n",
    "We can normalize the features with [Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization).\n",
    "\n",
    "```python\n",
    "tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1, dtype=None, mean=None, variance=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "`adapt` computes mean and std of the train data and store them as the layer's weights. `adapt`\n",
    " should be called before fit, evaluate, or predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1, dtype=None, mean=None, variance=None\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "print('Unnormalized row: ', df.iloc[:1].values)\n",
    "print('Normalized row: ', norm(df.iloc[:1]))\n",
    "print('Normalized df, mean row: ',norm(df.values).numpy().mean(1))\n",
    "print('Normalized df, std row: ',np.std(norm(df.values).numpy(), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "num_features =  9\n",
    "inputs_shape = (past, num_features)\n",
    "\n",
    "inputs = keras.layers.Input(shape=inputs_shape)\n",
    "inputs_norm = norm(inputs)\n",
    "rnn_out = keras.layers.SimpleRNN(32)(inputs_norm)\n",
    "outputs = keras.layers.Dense(1)(rnn_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `ModelCheckpoint` callback to regularly save checkpoints, and\n",
    "the `EarlyStopping` callback to interrupt training when the validation loss\n",
    "is not longer improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the loss with the function below. After one point, the loss stops\n",
    "decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:  Change the `keras.layers.SimpleRNN` layer to `keras.layers.LSTM` and to `keras.layers.GRU` and compare the results\n",
    "You can also set the `recurrent_dropout` parameter\n",
    "\n",
    "```python\n",
    "tf.keras.layers.x(\n",
    "    units,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_features = ...\n",
    "inputs_shape = (past, num_features)\n",
    "\n",
    "\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "inputs = layers.Input(shape=inputs_shape)\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "## complete the code\n",
    "lstm_out = layers...(...)(...)\n",
    "outputs = layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Wind velocity\n",
    "One thing that should stand out is the min value of the wind velocity, wv (m/s) and max. wv (m/s) columns. This -9999 is likely erroneous. There's a separate wind direction column, so the velocity should be >=0. Replace it with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = df['wv (m/s)']\n",
    "bad_wv = wv == -9999.0\n",
    "wv[bad_wv] = 0.0\n",
    "df['wv (m/s)'] = wv\n",
    "\n",
    "max_wv = df['max. wv (m/s)']\n",
    "bad_max_wv = max_wv == -9999.0\n",
    "max_wv[bad_max_wv] = 0.0\n",
    "df['max. wv (m/s)'] = max_wv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this will be easier for the model to interpret if you convert the wind direction and velocity columns to a wind vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = df.pop('wv (m/s)')\n",
    "\n",
    "# Convert to radians.\n",
    "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
    "\n",
    "# Calculate the wind x and y components.\n",
    "df['Wx'] = wv*np.cos(wd_rad)\n",
    "df['Wy'] = wv*np.sin(wd_rad)\n",
    "\n",
    "# Calculate the max wind x and y components.\n",
    "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
    "df['max Wy'] = max_wv*np.sin(wd_rad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly the Date Time column is very useful, but not in this string form. Start by converting it to seconds:\n",
    "\n",
    "\n",
    "Similar to the wind direction the time in seconds is not a useful model input. Being weather data it has clear daily and yearly periodicity. There are many ways you could deal with periodicity.\n",
    "\n",
    "A simple approach to convert it to a usable signal is to use sin and cos to convert the time to clear \"Time of day\" and \"Time of year\" signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp_s = df.index.map(datetime.timestamp)\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test\n",
    "split_fraction = 0.7\n",
    "train_split = int(split_fraction * int(len(df)))\n",
    "\n",
    "train_data = df.iloc[0 : train_split]\n",
    "val_data = df.iloc[train_split:]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = int(past / 1)\n",
    "\n",
    "dataset_train = prepare_dataset(train_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "dataset_val = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target= 'T (degC)')\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n",
    "inputs_shape = (inputs.shape[1], inputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset_train = dataset_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_val = dataset_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:  Use the same model as before and compare the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "num_features = ...\n",
    "inputs_shape = (past, num_features)\n",
    "\n",
    "inputs = layers.Input(shape=inputs_shape)\n",
    "inputs_norm = norm(inputs)\n",
    "## complete the code\n",
    "lstm_out = layers..(...)(...)\n",
    "outputs = layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:  Create a deep model stacking two recurrent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_features = ...\n",
    "inputs_shape = (past, num_features)\n",
    "\n",
    "\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "inputs = layers.Input(shape=inputs_shape)\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "## complete the code\n",
    "l_1 = keras.layers.LSTM(..., return_sequences=...)(...)\n",
    "l_2 = keras.layers.LSTM(..., return_sequences=...)(...)\n",
    "\n",
    "outputs = keras.layers.Dense(1)(...)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=...)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:  Use `Bidirectional`  layer\n",
    "\n",
    "```python\n",
    "layers.Bidirectional(layers.LSTM(64, return_sequences=)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(..., ...))\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "## complete the code\n",
    "l_1 = ...(...)\n",
    "\n",
    "outputs = keras.layers.Dense(1)(...)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=...)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:  Obtain a good model for predicting the temperature in 24h\n",
    "\n",
    "Try different architectures and different values for `past`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = ...\n",
    "batch_size = ...\n",
    "dataset_train = prepare_dataset(train_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "dataset_val = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target= 'T (degC)')\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n",
    "inputs_shape = (inputs.shape[1], inputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# dataset_train = dataset_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# dataset_val = dataset_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(dataset_train.map(lambda x, y: x))\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(..., ...))\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "\n",
    "l_1 = keras.layers.LSTM(..., return_sequences=...)(...)\n",
    "l_2 = keras.layers.LSTM(..., return_sequences=...)(...)\n",
    "\n",
    "outputs = keras.layers.Dense(1)(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        future,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "batch_size= 500\n",
    "dataset_ts = prepare_dataset(val_data, past, future,\n",
    "                    batch_size, target = 'T (degC)')\n",
    "for i, (x, y) in enumerate(dataset_ts):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print('batch: ', i)\n",
    "    pred = model.predict(x)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: Cryptocurrency Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, obtain and pre-process the data from [www.cryptodatadownload.com](www.cryptodatadownload.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.cryptodatadownload.com/cdd/gemini_{0}USD_1hr.csv\n",
    "# '../data/gemini_{0}USD_1hr.csv'\n",
    "def get_coin_df(fpath='../data/gemini_{0}USD_1hr.csv'):\n",
    "    coins = ['BTC', 'ETH', 'LTC', 'ZEC']\n",
    "    coins = ['BTC', 'ETH']\n",
    "    file_path = fpath.format('BTC')\n",
    "    print(file_path)\n",
    "    df = pd.read_csv(file_path, parse_dates=['Date'], skiprows=1, skipfooter=1)\n",
    "    df = df[['Date', 'Open']]\n",
    "    df = df.set_index('Date')\n",
    "    df = df.sort_index()\n",
    "    df = df.rename(columns={'Open': 'BTC'})\n",
    "    for coin in ['ETH', 'LTC', 'ZEC']:\n",
    "        coin_path = fpath.format(coin)\n",
    "        df_coin = pd.read_csv(coin_path,\n",
    "                              parse_dates=['Date'],\n",
    "                              skiprows=1,\n",
    "                              skipfooter=1)\n",
    "        df_coin = df_coin[['Date', 'Open']]\n",
    "        df_coin = df_coin.set_index('Date')\n",
    "        df_coin = df_coin.sort_index()\n",
    "        df_coin = df_coin.rename(columns={'Open': coin})\n",
    "        df[coin] = np.nan\n",
    "        df.loc[df_coin.index, coin] = df_coin.values.flatten()\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_coin_df(\n",
    "    fpath='http://www.cryptodatadownload.com/cdd/gemini_{0}USD_1hr.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.diff()\n",
    "# df[df.columns] = np.sqrt(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df_normalized = pd.DataFrame(x_scaled, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = ['BTC', 'ETH', 'LTC', 'ZEC']\n",
    "for col in coins:\n",
    "    df_normalized[col].plot(legend=True, figsize=(15, 7))\n",
    "plt.ylabel('Dolars scaled')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Time Series\n",
    "To start with, we will use only one cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_target = 'ETH' #  Coin that we want to predict, ['BTC', 'ETH', 'LTC', 'ZEC']\n",
    "df_coin = df[coin_target].copy()\n",
    "# delete nan rows\n",
    "df_coin = df_coin.dropna()\n",
    "df_coin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coin.plot(legend=True,figsize=(10,5))\n",
    "plt.ylabel(coin_target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate time series\n",
    "test_date = pd.Timestamp(\"2020-01-10\")\n",
    "init_date = pd.Timestamp(\"2017-10-08 14:00:00\")\n",
    "\n",
    "# train_data = df_coin.loc[df_coin.index < test_date].values\n",
    "\n",
    "train_data = df_coin.loc[(df_coin.index < test_date) *\n",
    "                         (df_coin.index > init_date)].values\n",
    "\n",
    "test_data = df_coin.loc[df_coin.index >= test_date].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = train_data.mean()\n",
    "sigma = train_data.std()\n",
    "print('mu, sigma: ', mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "train_data = (train_data - mu) / sigma\n",
    "test_data = (test_data - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform input array to time series matrix\n",
    "\n",
    "For example if  `dataset = [0,1,2,3,4,5,6]` :\n",
    "\n",
    "If we have `past=3`, and `future=2`, we use **windows of size 3** for predicting **2 steps ahead**.\n",
    "\n",
    "we are going to use `[0,1,2] (length=past=3)` to predict `4`, \n",
    "\n",
    "We need too create a training data like\n",
    "```python\n",
    "[0,1,2], 4 \n",
    "[1,2,3], 5 \n",
    "[2,3,4], 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def convert2matrix(data_arr, past, future, shuffle=False):\n",
    "    X, Y = [], []\n",
    "    size = len(data_arr)\n",
    "    for i in range(size - future - past + 1):\n",
    "        d = i + past\n",
    "        y_ind = i + past + future - 1\n",
    "        X.append(data_arr[i:d])\n",
    "        Y.append(data_arr[y_ind])\n",
    "    if shuffle:\n",
    "        c = list(zip(X, Y))\n",
    "        random.shuffle(c)\n",
    "        X, Y = zip(*c)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the function works, we should obtain:\n",
    "```python\n",
    "[0,1,2], 4 \n",
    "[1,2,3], 5 \n",
    "[2,3,4], 6\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trial, y_trial = convert2matrix(np.array([0, 1, 2, 3, 4, 5, 6]),\n",
    "                                  past=3,\n",
    "                                  future=2,\n",
    "                                  shuffle=False)\n",
    "for ind in range(len(y_trial)):\n",
    "    print(X_trial[ind, :], y_trial[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Create a model to predict the ETH value in 6h, `RMSE(test) < 30$`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows\n",
    "past, future = (..., 6)\n",
    "X_train, y_train = convert2matrix(train_data, past, future, shuffle=True)\n",
    "X_test, y_test = convert2matrix(test_data, past, future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0, :], y_test[0], test_data[:past + future]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(X_train)\n",
    "\n",
    "\n",
    "inputs_shape = (past, 1)\n",
    "inputs = keras.layers.Input(shape=(past, 1))\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "lstm_out_1 = layers.GRU(128, return_sequences=False) (inputs) \n",
    "lstm_out_1 = layers.Dropout(0.2)(lstm_out_1)\n",
    "lstm_out_1 = layers.Dense(8, activation='relu')(lstm_out_1)\n",
    "outputs = layers.Dense(1)(lstm_out_1)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_split=0.2, shuffle=True, batch_size = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten() * sigma + mu\n",
    "y_target = y_test * sigma + mu\n",
    "diff = y_pred - y_target\n",
    "print('max deviation: ', np.abs(y_pred - y_target).max())\n",
    "print('RMSE: ', np.mean((y_pred - y_target)**2)**0.5)\n",
    "print('MAE: ', np.abs(y_pred - y_target).mean())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(y_target[:15000])\n",
    "plt.plot(y_pred[:15000])\n",
    "plt.legend(['True {0}'.format(coin_target), 'Predictions {0}'.format(coin_target)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can try feature engineering with df\n",
    "coin_target = 'ETH' # 'BTC'\n",
    "coins =  ['ETH', 'LTC', 'ZEC', 'BTC'] # ['BTC', 'ETH', 'LTC', 'ZEC']\n",
    "df_multi = df[coins].dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2matrix_multi(df, past, future, target, shuffle=False):\n",
    "    X, Y = [], []\n",
    "    size = len(df)\n",
    "    for i in range(size - future - past + 1):\n",
    "        d = i + past\n",
    "        y_ind = i + past + future - 1\n",
    "        X.append(df.iloc[i:d, :].values)\n",
    "        Y.append(df.iloc[y_ind][target])\n",
    "    if shuffle:\n",
    "        c = list(zip(X, Y))\n",
    "        random.shuffle(c)\n",
    "        X, Y = zip(*c)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "#train_data = df_multi.loc[df_multi.index < test_date, :]\n",
    "train_data = df_multi.loc[(df_multi.index < test_date) * (df_multi.index > init_date ), : ].copy()\n",
    "test_data = df_multi.loc[df_multi.index >= test_date, :].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_dict = {}\n",
    "sigma_dict = {}\n",
    "for c in coins:\n",
    "    mu = train_data[c].mean()\n",
    "    sigma = train_data[c].std()\n",
    "    mu_dict[c] = mu\n",
    "    sigma_dict[c] = sigma\n",
    "    print('coin: {0} , mu,sigma'.format(c), mu, sigma)\n",
    "print(mu_dict, sigma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in coins:\n",
    "    mu = mu_dict[c]\n",
    "    sigma = sigma_dict[c]\n",
    "    train_data.loc[:, c] = (train_data[c].values - mu) / sigma\n",
    "    test_data.loc[:, c] = (test_data[c].values - mu) / sigma\n",
    "train_data.describe()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Create a model to predict the ETH value in 6h, `RMSE(test) < 30$`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create windows\n",
    "past, future = (..., 6)\n",
    "X_train, y_train = convert2matrix_multi(\n",
    "    train_data, past, future, target=coin_target, shuffle=True)\n",
    "X_test, y_test = convert2matrix_multi(\n",
    "    test_data, past, future, target=coin_target, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1\n",
    ")\n",
    "norm.adapt(X_train)\n",
    "\n",
    "\n",
    "inputs = keras.layers.Input(shape=(past, len(coins)))\n",
    "inputs_norm = norm(inputs)\n",
    "\n",
    "\n",
    "'''lstm_out_1 =  layers.LSTM(64, return_sequences=True)(inputs)\n",
    "lstm_out_1 =  layers.LSTM(64, return_sequences=False)(lstm_out_1)\n",
    "lstm_out_1 = layers.Dropout(0.4)(lstm_out_1)\n",
    "lstm_out_1 = layers.Dense(8, activation='relu')(lstm_out_1)\n",
    "outputs = layers.Dense(1)(lstm_out_1)\n",
    "'''\n",
    "\n",
    "lstm_out_1 = layers.GRU(128, return_sequences=False) (inputs) \n",
    "lstm_out_1 = layers.Dropout(0.2)(lstm_out_1)\n",
    "#lstm_out_1 = layers.Dense(8, activation='relu')(lstm_out_1)\n",
    "outputs = layers.Dense(1)(lstm_out_1)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_split=0.2, shuffle=True, batch_size = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = sigma_dict[coin_target]\n",
    "mu = mu_dict[coin_target]\n",
    "y_pred = model.predict(X_test).flatten() * sigma + mu\n",
    "y_target = y_test * sigma + mu\n",
    "diff = y_pred - y_target\n",
    "print('max deviation: ', np.abs(y_pred - y_target).max())\n",
    "print('RMSE: ', np.mean((y_pred - y_target)**2)**0.5)\n",
    "print('MAE: ', np.abs(y_pred - y_target).mean())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(y_target)\n",
    "plt.plot(y_pred)\n",
    "plt.legend(['True {0}'.format(coin_target), 'Predictions {0}'.format(coin_target)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/rnn\n",
    "\n",
    "https://keras.io/examples/timeseries/timeseries_weather_forecasting/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
