{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Cualquier librería adicional que necesiteis durante el ejercicio, importadlo en esta sección \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Este ejercicio pretende poner en práctica la habilidad de limpiar datos y visualizar plots en para crear finalmente modelos en __sklearn__.\n",
    "\n",
    "El estudiante tendrá que repasar los comandos realizados en clase y lidiar con posibles errores durante el desarrollo. \n",
    "\n",
    "Para facilitar y agilizar el desarrollo, el estudiante tendrá que rellenar los huecos marcados como '_# codigo-alumno_'. No obstante, si además el estudiante necesita ejecutar código adicional, siempre podrá utilizar cualquier celda adicional. \n",
    "\n",
    "El estudiante tendrá siempre que introducir una semilla (seed) que generará acorde a su fecha de nacimiento (sin ser intrusivos en edad).\n",
    "\n",
    "Finalmente, la entrega será un fichero .ipynb cambiando nombre y apellido al fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" El estudiante tendrá que utilizar la semilla proporcionada para todos los procesos aleatorios \"\"\"\n",
    "\n",
    "seed = #dia-nacimiento-estudiante + 13 * mes-nacimiento-estudiante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Leed el dataframe de sklearn llamado 'fetch_kddcup99' y almacenarlo en una variable llamada data \"\"\"\n",
    "\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "\n",
    "data = fetch_kddcup99(as_frame=True)\n",
    "pd_data = data.frame\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" De entre todas las variables del dataframe, solo trabajaremos en \n",
    "    este ejercicio con las descritas en key_columns, por lo que tendréis que quitar el resto \"\"\"\n",
    "\n",
    "key_columns = ['duration', 'protocol_type', 'service', 'flag', 'logged_in', 'count', 'srv_count', 'serror_rate', 'dst_host_srv_count', 'dst_host_srv_serror_rate', 'labels']\n",
    "\n",
    "pd_data = pd_data[key_columns]\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Comprobad que no haya nulos ni registros duplicados \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Mostrar un barplot para la variable objetivo (labels)\"\"\"\n",
    "\n",
    "target = 'labels'\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Dado que hay dos etiquetas que se repiten con mayor frecuencia, \n",
    "    transformad la variable labels para que tenga un valor booleano que indique \n",
    "    si es la etiqueta más frecuente o la segunda más frecuente, \n",
    "    los demás registros los eliminaremos de este estudio \"\"\"\n",
    "\n",
    "# codigo-alumno\n",
    "\n",
    "print(len(pd_data))\n",
    "pd_data.groupby('labels').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Volved a mostrar el barplot para la variable objetivo (labels) \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Separaremos las variables categóricas de las numéricas \"\"\"\n",
    "\n",
    "\n",
    "num_cols = ['duration', 'count', 'srv_count', 'serror_rate', 'dst_host_srv_count', 'dst_host_srv_serror_rate']\n",
    "cat_cols = ['protocol_type', 'service', 'flag', 'logged_in']\n",
    "\n",
    "pd_data[num_cols] = pd_data[num_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Mostrad un histograma por cada variable numérica \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Por la forma de los histogramas, podría ser un buen estudio convertir las variables\n",
    "    numéricas a variables dummy, es lo que hareis en este apartado y, por tanto, pasarán \n",
    "    a ser categóricas todas las variables del dataframe. Esta parte será libre para el \n",
    "    estudiante. Deberá tomar la decisión que considere más apropiada para realizar esta \n",
    "    binarización \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Mostrad un barplot por cada variable \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Transformad la variable service en una variable dummy que nos permitan identificar el servicio\n",
    "    más frecuente frente al resto \"\"\"\n",
    "\n",
    "# codigo-alumno\n",
    "\n",
    "pd_data.groupby('service').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Transformad la variable flag en dos variables dummy que nos permitan identificar 3 tipos de flags, \n",
    "    los dos más comunes y el resto \"\"\"\n",
    "\n",
    "# codigo-alumno\n",
    "\n",
    "pd_data.groupby('flag').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Volved a mostrad un barplot por cada variable \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Mostrad un plot de correlaciones entre variables numéricas \"\"\"\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Realizad una evaluación de, al menos, cinco modelos de machine learning con\n",
    "    la técnica de validación cruzada más acertada (10 splits). Además, se pide\n",
    "    incorporar, al menos, una técnica de selección previa de las 1, 2 o 3 features que\n",
    "    mejores resultados ofrezca (Nota, tendreis que usar OneHotEncoder para las variables \n",
    "    que tengan strings) \"\"\"\n",
    "\n",
    "X = pd_data.drop(target, axis=1) \n",
    "y = pd_data[target]\n",
    "\n",
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
