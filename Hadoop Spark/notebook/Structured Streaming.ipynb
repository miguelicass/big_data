{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Structured Streaming: convirtiendo consultas batch en streaming"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<p><b>PARA SABER M\u00c1S</b>: Notebook interesante sobre Structured Streaming hecho por Databricks \n    <a target = \"_blank\" href=\"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html\">aqu\u00ed</a>\n</p>\n</div>\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Descripci\u00f3n de las variables"}, {"cell_type": "markdown", "metadata": {}, "source": "El dataset est\u00e1 compuesto por las siguientes variables:\n\n1. **Year** 2008\n2. **Month** 1\n3. **DayofMonth** 1-31\n4. **DayOfWeek** 1 (Monday) - 7 (Sunday)\n5. **DepTime** hora real de salida (local, hhmm)\n6. **CRSDepTime** hora prevista de salida (local, hhmm)\n7. **ArrTime** hora real de llegada (local, hhmm)\n8. **CRSArrTime** hora prevista de llegada (local, hhmm)\n9. **UniqueCarrier** c\u00f3digo del aparato\n10. **FlightNum** n\u00famero de vuelo\n11. **TailNum** identificador de cola: aircraft registration, unique aircraft identifier\n12. **ActualElapsedTime** tiempo real invertido en el vuelo\n13. **CRSElapsedTime** en minutos\n14. **AirTime** en minutos\n15. **ArrDelay** retraso a la llegada, en minutos: se considera que un vuelo ha llegado \"on time\" si aterriz\u00f3 menos de 15 minutos m\u00e1s tarde de la hora prevista en el Computerized Reservations Systems (CRS).\n16. **DepDelay** retraso a la salida, en minutos\n17. **Origin** c\u00f3digo IATA del aeropuerto de origen\n18. **Dest** c\u00f3digo IATA del aeropuerto de destino\n19. **Distance** en millas\n20. **TaxiIn** taxi in time, in minutes\n21. **TaxiOut** taxi out time in minutes\n22. **Cancelled** *si el vuelo fue cancelado (1 = s\u00ed, 0 = no)\n23. **CancellationCode** raz\u00f3n de cancelaci\u00f3n (A = aparato, B = tiempo atmosf\u00e9rico, C = NAS, D = seguridad)\n24. **Diverted** *si el vuelo ha sido desviado (1 = s\u00ed, 0 = no)\n25. **CarrierDelay** en minutos: El retraso del transportista est\u00e1 bajo el control del transportista a\u00e9reo. Ejemplos de sucesos que pueden determinar el retraso del transportista son: limpieza de la aeronave, da\u00f1o de la aeronave, espera de la llegada de los pasajeros o la tripulaci\u00f3n de conexi\u00f3n, equipaje, impacto de un p\u00e1jaro, carga de equipaje, servicio de comidas, computadora, equipo del transportista, problemas legales de la tripulaci\u00f3n (descanso del piloto o acompa\u00f1ante) , da\u00f1os por mercanc\u00edas peligrosas, inspecci\u00f3n de ingenier\u00eda, abastecimiento de combustible, pasajeros discapacitados, tripulaci\u00f3n retrasada, servicio de inodoros, mantenimiento, ventas excesivas, servicio de agua potable, denegaci\u00f3n de viaje a pasajeros en mal estado, proceso de embarque muy lento, equipaje de mano no v\u00e1lido, retrasos de peso y equilibrio.\n26. **WeatherDelay** en minutos: causado por condiciones atmosf\u00e9ricas extremas o peligrosas, previstas o que se han manifestado antes del despegue, durante el viaje, o a la llegada.\n27. **NASDelay** en minutos: retraso causado por el National Airspace System (NAS) por motivos como condiciones meteorol\u00f3gicas (perjudiciales pero no extremas), operaciones del aeropuerto, mucho tr\u00e1fico a\u00e9reo, problemas con los controladores a\u00e9reos, etc.\n28. **SecurityDelay** en minutos: causado por la evacuaci\u00f3n de una terminal, re-embarque de un avi\u00f3n debido a brechas en la seguridad, fallos en dispositivos del control de seguridad, colas demasiado largas en el control de seguridad, etc.\n29. **LateAircraftDelay** en minutos: debido al propio retraso del avi\u00f3n al llegar, problemas para conseguir aterrizar en un aeropuerto a una hora m\u00e1s tard\u00eda de la que estaba prevista."}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2020-11-14 08:42:53--  https://github.com/olbapjose/xapi-clojure/raw/master/flightsFolder.zip\nResolving github.com (github.com)... 140.82.121.4\nConnecting to github.com (github.com)|140.82.121.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flightsFolder.zip [following]\n--2020-11-14 08:42:54--  https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flightsFolder.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2728655 (2.6M) [application/zip]\nSaving to: \u2018flightsFolder.zip\u2019\n\nflightsFolder.zip   100%[===================>]   2.60M  --.-KB/s    in 0.09s   \n\n2020-11-14 08:42:54 (28.8 MB/s) - \u2018flightsFolder.zip\u2019 saved [2728655/2728655]\n\nArchive:  flightsFolder.zip\n   creating: flightsFolder/\n  inflating: flightsFolder/flights0.csv  \n  inflating: flightsFolder/flights1.csv  \n  inflating: flightsFolder/flights2.csv  \n  inflating: flightsFolder/flights3.csv  \n  inflating: flightsFolder/flights4.csv  \n  inflating: flightsFolder/flights5.csv  \n  inflating: flightsFolder/flights6.csv  \n  inflating: flightsFolder/flights7.csv  \n  inflating: flightsFolder/flights8.csv  \n  inflating: flightsFolder/flights9.csv  \n20/11/14 08:43:00 WARN hdfs.DataStreamer: Caught exception\njava.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Thread.join(Thread.java:1252)\n\tat java.lang.Thread.join(Thread.java:1326)\n\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:980)\n\tat org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:844)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:840)\n20/11/14 08:43:00 WARN hdfs.DataStreamer: Caught exception\njava.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Thread.join(Thread.java:1252)\n\tat java.lang.Thread.join(Thread.java:1326)\n\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:980)\n\tat org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:630)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:807)\n"}], "source": "!wget https://github.com/olbapjose/xapi-clojure/raw/master/flightsFolder.zip\n!unzip flightsFolder.zip\n!hdfs dfs -copyFromLocal flightsFolder /tmp"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 10 items\n-rw-r--r--   2 root hadoop    1043070 2020-11-14 08:43 /tmp/flightsFolder/flights0.csv\n-rw-r--r--   2 root hadoop    1042032 2020-11-14 08:43 /tmp/flightsFolder/flights1.csv\n-rw-r--r--   2 root hadoop    1042990 2020-11-14 08:43 /tmp/flightsFolder/flights2.csv\n-rw-r--r--   2 root hadoop    1048563 2020-11-14 08:43 /tmp/flightsFolder/flights3.csv\n-rw-r--r--   2 root hadoop    1043098 2020-11-14 08:43 /tmp/flightsFolder/flights4.csv\n-rw-r--r--   2 root hadoop    1028731 2020-11-14 08:43 /tmp/flightsFolder/flights5.csv\n-rw-r--r--   2 root hadoop    1034014 2020-11-14 08:43 /tmp/flightsFolder/flights6.csv\n-rw-r--r--   2 root hadoop    1068041 2020-11-14 08:43 /tmp/flightsFolder/flights7.csv\n-rw-r--r--   2 root hadoop    1028067 2020-11-14 08:43 /tmp/flightsFolder/flights8.csv\n-rw-r--r--   2 root hadoop    1044834 2020-11-14 08:43 /tmp/flightsFolder/flights9.csv\n"}], "source": "!hdfs dfs -ls /tmp/flightsFolder"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2020-11-14 08:44:54--  https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flights_jan08.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9719583 (9.3M) [text/plain]\nSaving to: \u2018flights_jan08.csv\u2019\n\nflights_jan08.csv   100%[===================>]   9.27M  --.-KB/s    in 0.1s    \n\n2020-11-14 08:44:54 (74.2 MB/s) - \u2018flights_jan08.csv\u2019 saved [9719583/9719583]\n\n"}], "source": "!wget https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flights_jan08.csv\n!hdfs dfs -copyFromLocal flights_jan08.csv /tmp"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "import pyspark.sql.functions as F\nfrom pyspark.sql.types import IntegerType\n\n# Leemos los datos, quitamos filas con NA y convertimos a num\u00e9rico\nflightsDF = spark.read\\\n                 .option(\"header\", \"true\")\\\n                 .option(\"inferSchema\", \"true\")\\\n                 .csv(\"/tmp/flights_jan08.csv\")\n\ncleanFlightsDF = flightsDF.where(\"ArrDelay != 'NA' and DepDelay != 'NA'\")\\\n                          .withColumn(\"ArrDelay\", F.col(\"ArrDelay\").cast(IntegerType()))\\\n                          .withColumn(\"DepDelay\", F.col(\"DepDelay\").cast(IntegerType()))\\\n                          .withColumn(\"ArrDelayCat\", F.when(F.col(\"ArrDelay\") < 15, \"None\")\\\n                                                      .when((F.col(\"ArrDelay\") >= 15) & (F.col(\"ArrDelay\") < 60), \"Slight\")\\\n                                                      .otherwise(\"Huge\"))\\\n                          .cache() # we will be working with it from now on!"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- Year: integer (nullable = true)\n |-- Month: integer (nullable = true)\n |-- DayofMonth: integer (nullable = true)\n |-- DayOfWeek: integer (nullable = true)\n |-- DepTime: string (nullable = true)\n |-- CRSDepTime: integer (nullable = true)\n |-- ArrTime: string (nullable = true)\n |-- CRSArrTime: integer (nullable = true)\n |-- UniqueCarrier: string (nullable = true)\n |-- FlightNum: integer (nullable = true)\n |-- TailNum: string (nullable = true)\n |-- ActualElapsedTime: string (nullable = true)\n |-- CRSElapsedTime: integer (nullable = true)\n |-- AirTime: string (nullable = true)\n |-- ArrDelay: integer (nullable = true)\n |-- DepDelay: integer (nullable = true)\n |-- Origin: string (nullable = true)\n |-- Dest: string (nullable = true)\n |-- Distance: integer (nullable = true)\n |-- TaxiIn: string (nullable = true)\n |-- TaxiOut: string (nullable = true)\n |-- Cancelled: integer (nullable = true)\n |-- CancellationCode: string (nullable = true)\n |-- Diverted: integer (nullable = true)\n |-- CarrierDelay: string (nullable = true)\n |-- WeatherDelay: string (nullable = true)\n |-- NASDelay: string (nullable = true)\n |-- SecurityDelay: string (nullable = true)\n |-- LateAircraftDelay: string (nullable = true)\n |-- ArrDelayCat: string (nullable = false)\n\n"}], "source": "cleanFlightsDF.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Agregaciones en streaming"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<p><b>PREGUNTA</b>: \u00bfCu\u00e1l es el retraso medio por cada destino para vuelos que salen de SFO?\n    Convierte esta consulta en streaming</p>\n</div>"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|  32.9639175257732|\n| MDW|28.229885057471265|\n| LAX|23.899497487437184|\n| SAN| 28.80275229357798|\n+----+------------------+\n\n"}], "source": "def retrasoMedioDestDesdeSFO(df):\n    return df.filter(F.col(\"Origin\") == \"SFO\")\\\n              .groupBy(\"Dest\").agg(F.mean(\"ArrDelay\").alias(\"Average_delay\"))\n\nres = retrasoMedioDestDesdeSFO(cleanFlightsDF)\nres.show()"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "flightsSchema = cleanFlightsDF.schema # in Structured Streaming the schema is mandatory\n\nstreamingFlights = spark.readStream.schema(flightsSchema)\\\n                        .option(\"maxFilesPerTrigger\", 1)\\\n                        .csv(\"/tmp/flightsFolder\") # read 1 file in each operation\n\n# Operaci\u00f3n de agregaci\u00f3n, igual que con un DataFrame convencional\n# COMPLETA LA CONSULTA: de los vuelos que salen de SFO, calcular el retraso medio para cada destino\nlargestAverageSFOstreamingDF = retrasoMedioDestDesdeSFO(streamingFlights)\n\n# largestAverageSFOstreamingDF = streamingFlights.where(\"Origin = 'SFO'\")\\\n#                                                .groupBy(\"Dest\")\\\n#                                                .agg(F.mean(\"ArrDelay\").alias(\"Retraso\"))\n\n# Ahora escribimos continuamente el resultado. Solo para test, escribimos en memoria\ncountQuery = largestAverageSFOstreamingDF\\\n                .writeStream\\\n                .queryName(\"meanArrDelaySFO\")\\\n                .format(\"memory\")\\\n                .outputMode(\"complete\")\\\n                .start() # esto lanza el stream\n\n# Puesto que el driver es este notebook de Jupyter y no lo pensamos cerrar,\n# hasta que hayamos visualizado correctamente todas las salidas, entonces podemos omitir la l\u00ednea siguiente\n\n#countQuery.awaitTermination() # obligatorio en aplicaciones en producci\u00f3n para evitar que finalice el driver"}, {"cell_type": "markdown", "metadata": {}, "source": "### Escribir en memoria implica que se crea una tabla autom\u00e1ticamente en memoria con el nombre de la consulta"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+-------------+\n|Dest|Average_delay|\n+----+-------------+\n+----+-------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|              18.8|\n| MDW|41.416666666666664|\n| LAX|              40.0|\n| SAN|24.925925925925927|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|           40.9375|\n| MDW|29.136363636363637|\n| LAX|              26.5|\n| SAN|20.796610169491526|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS| 41.42307692307692|\n| MDW|26.870967741935484|\n| LAX| 25.47761194029851|\n| SAN|25.864197530864196|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS| 43.04054054054054|\n| MDW|27.027027027027028|\n| LAX|24.402298850574713|\n| SAN|26.427083333333332|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS| 38.78947368421053|\n| MDW|28.891304347826086|\n| LAX|24.036363636363635|\n| SAN| 30.30081300813008|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS| 40.30769230769231|\n| MDW|27.448275862068964|\n| LAX| 21.66412213740458|\n| SAN|28.213793103448275|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|38.184615384615384|\n| MDW|27.208955223880597|\n| LAX|21.767123287671232|\n| SAN| 30.50943396226415|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS| 36.17218543046358|\n| MDW| 29.77777777777778|\n| LAX|22.869565217391305|\n| SAN| 29.65921787709497|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|             33.68|\n| MDW|30.012345679012345|\n| LAX|             22.68|\n| SAN|29.915841584158414|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|  32.9639175257732|\n| MDW|28.229885057471265|\n| LAX|23.899497487437184|\n| SAN| 28.80275229357798|\n+----+------------------+\n\n+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|  32.9639175257732|\n| MDW|28.229885057471265|\n| LAX|23.899497487437184|\n| SAN| 28.80275229357798|\n+----+------------------+\n\n"}], "source": "import time \n\nresultDF = spark.sql(\"select * from meanArrDelaySFO\")\n\ntime.sleep(10)\n\nresultDF.show()\n\ntime.sleep(10)\n\nresultDF.show()\n\nfor i in range(10):\n    time.sleep(1)\n#    resultDF.write.csv(\"/tmp/result\" + str(i) + \".csv\")\n    resultDF.show()\n"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|  32.9639175257732|\n| MDW|28.229885057471265|\n| LAX|23.899497487437184|\n| SAN| 28.80275229357798|\n+----+------------------+\n\n"}], "source": "resultDF.show()"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+------------------+\n|Dest|     Average_delay|\n+----+------------------+\n| LAS|  32.9639175257732|\n| MDW|28.229885057471265|\n| LAX|23.899497487437184|\n| SAN| 28.80275229357798|\n+----+------------------+\n\n"}], "source": "resultDF.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.12"}}, "nbformat": 4, "nbformat_minor": 2}