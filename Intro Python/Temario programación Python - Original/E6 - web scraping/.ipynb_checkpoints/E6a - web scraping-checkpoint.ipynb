{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción, HTML\n",
    "\n",
    "Mucha información está simplemente accesible en Internet. En este pequeño script vemos que es fácil acceder a ella, recopilarla, buscarla, procesarla.\n",
    "\n",
    "El método más usado por los humanos para acceder a esa infomración de Internet es navegando mediante un navegador. El *Web Scraping* es la extracción de información que hay en sitios web, mediante programas de software\n",
    "\n",
    "El contenido de las páginas web está escrito en archivos HTML. Veamos uno como ejemplo. En él, la información se organiza jerárquicamente: los distintos bloques de información están contenidos unos en otros, y se marcan con etiquetas. Mejor que cualquier explicación es verlo examinando el código fuente de cualquier página web.\n",
    "Empezamos con un archivo html muy pequeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "    <head>\n",
      "        <title>\n",
      "            A web page\n",
      "        </title>\n",
      "    </head>\n",
      "    <body>\n",
      "        <p id=\"author\">Joel Grus</p>\n",
      "        <p id=\"subject\">Data Science</p>\n",
      "    </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pequenno_codigo_html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <title>\n",
    "            A web page\n",
    "        </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p id=\"author\">Joel Grus</p>\n",
    "        <p id=\"subject\">Data Science</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "print(pequenno_codigo_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "Empezamos por ver cómo se puede manejar un fragmento de texto html cualquiera, tanto si viene de Internet o si lo tenemos en nuestro equipo.\n",
    "\n",
    "Para manejar la estructura de un archivo html, vamos a usar la librería BeautifulSoup. Esto requiere instalar el paquete bs4. Veamos las operaciones básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joel Grus\n",
      "-----------------------\n",
      "['Joel', 'Grus']\n",
      "author\n",
      "[<p id=\"author\">Joel Grus</p>, <p id=\"subject\">Data Science</p>]\n",
      "Joel Grus\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup_pequenno_codigo = BeautifulSoup(pequenno_codigo_html, \"lxml\")\n",
    "primer_parrafo = soup_pequenno_codigo.find('p')\n",
    "\n",
    "print(primer_parrafo.text)\n",
    "print(\"-----------------------\")\n",
    "print(primer_parrafo.text.split())\n",
    "print(primer_parrafo[\"id\"])\n",
    "todos_los_parrafos = soup_pequenno_codigo.find_all('p')\n",
    "print(todos_los_parrafos)\n",
    "print(todos_los_parrafos[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora con una página web real:\n",
    "\n",
    "    http://antares.sip.ucm.es/cpareja/\n",
    "\n",
    "Examínala. Verás lo siguiente:\n",
    "\n",
    "<img src=\"./images/cpareja.png\" width=\"450\">\n",
    "\n",
    "Cada navegador ofrece sus propio modo de examinar  el codigo fuente en html. En el mío, pulsando el botón derecho se pued seleccionar la opción *Ver el código fuente de la página*, y tenemos lo siguiente:\n",
    "\n",
    "<img src=\"./images/cpareja-fuente.png\" width=\"450\">\n",
    "\n",
    "Para descargar páginas html de Internet, necesitamos la librería `requests` de Python.\n",
    "\n",
    "Esta página que acabamos de abrir es más larga y completa que la del ejemplo anterior, así que una vez descargado su código fuente no vamos a mostrarla entera; nosotros optamos por ver únicamente su principio y su final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n",
      "\r\n",
      "<!--\r\n",
      "  Design by Free CSS Templates\r\n",
      "  http://www.freecsstemplates.org\r\n",
      "  Released for free under a Creative Commons Attribution 2.5 L\n",
      ".........................................\n",
      "  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\r\n",
      "    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\r\n",
      "  })();\r\n",
      "\r\n",
      "</script>\r\n",
      "</body>\r\n",
      "\r\n",
      "</html>\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "mi_url = \"http://antares.sip.ucm.es/cpareja/\"\n",
    "mi_codigo_html = requests.get(mi_url).text\n",
    "print(mi_codigo_html[:250])\n",
    "print(\".........................................\")\n",
    "print(mi_codigo_html[-250:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a usar funciones de la librería para extraer distintos tipos de elementos de dicha página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta content=\"\" name=\"keywords\"/>\n",
      "<meta content=\"\" name=\"description\"/>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "<title>CristÃ³bal Pareja Flores, pÃ¡gina web</title>\n",
      "<link href=\"./style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "</head>\n",
      "-----------------------\n",
      "<p class=\"meta\">\n",
      "<span class=\"date\">Curso 2013-14</span><span class=\"posted\">Actualizado: 2014-abril-06</span>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "mi_pag_web = BeautifulSoup(mi_codigo_html, \"lxml\")\n",
    "print(mi_pag_web.find('head'))\n",
    "print(\"-----------------------\")\n",
    "print(mi_pag_web.find('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "-----------------------\n",
      "<p class=\"meta\">\n",
      "<span class=\"date\">2015</span><span class=\"posted\">Actualizado: 2015-abril-6</span>\n",
      "</p>\n",
      "-----------------------\n",
      "[<p class=\"meta\">\n",
      "<span class=\"date\">Curso 2013-14</span><span class=\"posted\">Actualizado: 2014-abril-06</span>\n",
      "</p>, <p class=\"meta\">\n",
      "<span class=\"date\">Hasta 2014</span><span class=\"posted\">Actualizado: 2014-dic-23</span>\n",
      "</p>, <p class=\"meta\">\n",
      "<span class=\"date\">2015</span><span class=\"posted\">Actualizado: 2015-abril-6</span>\n",
      "</p>, <p class=\"meta\">\n",
      "<span class=\"date\">Hasta 2014</span><span class=\"posted\">Actualizado: 2014-abril-6</span>\n",
      "</p>]\n",
      "-----------------------\n",
      "46\n",
      "<a href=\"http://eprints.ucm.es/8705/1/CUADERNO_DE_TRABAJO_8.pdf\">manual</a>\n",
      "http://eprints.ucm.es/8705/1/CUADERNO_DE_TRABAJO_8.pdf\n",
      "manual\n"
     ]
    }
   ],
   "source": [
    "print(len(mi_pag_web.find_all('p')))\n",
    "print(\"-----------------------\")\n",
    "print(mi_pag_web.find_all('p')[8])\n",
    "print(\"-----------------------\")\n",
    "print(mi_pag_web.find_all('p', {'class': 'meta'}))\n",
    "print(\"-----------------------\")\n",
    "anclas_o_hiperenlaces = mi_pag_web.find_all('a')\n",
    "print(len(anclas_o_hiperenlaces))\n",
    "print(anclas_o_hiperenlaces[3])\n",
    "print(anclas_o_hiperenlaces[3].get(\"href\"))\n",
    "print(anclas_o_hiperenlaces[3].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los contenidos están estructurados en distintos contenedores identifidados por distintas etiquetas en el documento `html`. Para acceder a estos contenidos, se han de usar funciones de la librería, de la manera que se ha mostrado, y con ellos se pueden extraer distintos tipos de elementos de la página y posteriormente procesarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "Hay multitud de referencias a las funciones y métodos disponibles en esta librería, y hay multitud de ejemplos en Internet. Damos únicamente un par de dichas referencias.\n",
    "\n",
    "<ol>\n",
    "    <li> Del libro \"Data Science from Scratch\", de Joel Grus, capítulo 9 (\"Getting Data\"), el apartado \"Scraping the Web\".\n",
    "    <li> La página oficial de documentación de esta librería:\n",
    "        https://pypi.org/project/beautifulsoup4/\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
